{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/all_haiku.csv')\n",
    "\n",
    "data = data.iloc[0:1000]\n",
    "\n",
    "data['haiku'] = data['0']+' '+data['1']+' '+data['2']\n",
    "\n",
    "data['haiku'] = data['haiku'].apply(lambda x: str(x).strip().replace('-','').lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 50931 long\n",
      "Text has 2728 unique characters\n"
     ]
    }
   ],
   "source": [
    "#Leer los datos\n",
    "\n",
    "text = ''\n",
    "\n",
    "for i in data['haiku']:\n",
    "    text += i + ' '\n",
    "\n",
    "#vocab = sorted(set(text))\n",
    "vocab = sorted(set(list(filter(lambda x: x != \"\", text.split(\" \")))))\n",
    "\n",
    "print(f'Text is {len(text)} long')\n",
    "print(f'Text has {len(vocab)} unique characters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento del texto\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "txt_words = list(filter(lambda x: x != \"\", text.split(\" \")))\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in txt_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing\n",
      "boats\n",
      "colors\n",
      "of\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(txt_words)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n",
      "\"thesoundofgeesedrownedbythesoundofthetrainthismorningautumnsunmyshadowovertombstonesflyfishing;thesoundofthewindinthereeldecemberalongshadowjoinsanotherendofpathsnowflakesmeltingonthepondmorningfrostsheleavesfirsteveningwalksmelloftarbetweenpinesdachauablueskyabovethechimneysdeepautumn;theapplecolderinthetree.visitingthegravesstrongertheoctoberwindatmygrandparents'overthehedgeadragonflyeastabubbleburstsonsurfacefullmoonrainthewhitelilaclowmyhandon\"\n",
      "\"herhipfullmoonthreepetalsfallfromthepurpleconeflower...almostsummerinstantmessagemoonrevealsmoreofherselfeachnightoutofthewellbythebucketihuntamoonnudebeachastrangercoversmewithhisshadowgardenweddingunderthecherryblossomsthebride'sblushdeepensrainynewyorkfromthetenthstoreywindowblackumbrellasbloomdrunkonthebeachthemooninmysakecupdisappearsfaintlypurpleagainstthemoonpinesinthelightthelastlightofday~purplerhododendronsdissolveinthedarkwisteriabloomingbeforetheendof\"\n",
      "'rainthroughlace~thetraceryoffrostonglassrainfallsfromthetreesontheblueiriswinterbeachthreegreylinesofsand,seaandskywinterwhitepeoniesinfallingsnowlongillness–pinkdogwoodbloomingwithoutmelunchalfrescoleavingoutachairforthesuntheattentionhisdoggetshomelessmanrememberingasongfrommychildhoodplumblossomsfather’spillsthepaletteofautumnleavesendofsummerourmemoriesinzipfileswakingupwithfreckles&curlssummerbreaklongnightonmywindow—aspiderclimbingthemoontrain'\n",
      "'windowthefingerprintsfrompastjourneysoldloveletterthecrinklededgesofpoppypetalshisscentgonefromeveryroomwinterjasmineovernightsnowhissideofthebeduntouchedforesttrailrunningtotheendofmythoughtslearningtoeataroundbruiseswinterappleswinternightextendingmywordonscrabblethumbingthroughanoldrolodexwinterlightdandelionfieldmyvoicedissipatesinthewindtrailingbehindtheotherhikerstasteofdustsummerbreakthesunscattersmyfrecklessummer’sendinajarofshellsthesmellofsaltairearlymorningdewsqueezingthe'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehand\"\n",
      "Target data:  \"boatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0\n",
      "   input: (891, \"'fishing'\")\n",
      "   expected output: (257, \"'boats'\")\n",
      "Step     1\n",
      "   input: (257, \"'boats'\")\n",
      "   expected output: (516, \"'colors'\")\n",
      "Step     2\n",
      "   input: (516, \"'colors'\")\n",
      "   expected output: (1643, \"'of'\")\n",
      "Step     3\n",
      "   input: (1643, \"'of'\")\n",
      "   expected output: (2405, \"'the'\")\n",
      "Step     4\n",
      "   input: (2405, \"'the'\")\n",
      "   expected output: (1879, \"'rainbow'\")\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(f'Step     {i}')\n",
    "    print(f'   input: {int(input_idx), repr(idx2char[input_idx])}')\n",
    "    print(f'   expected output: {int(target_idx), repr(idx2char[target_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 2728) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           698368    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 2728)          2796200   \n",
      "=================================================================\n",
      "Total params: 7,432,872\n",
      "Trainable params: 7,432,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2535, 2386, 2724,  497,  433, 2467, 1735, 2119, 2280, 1937, 2147,\n",
       "        848,  263, 2726,  408, 2180, 1395, 1012,   41,  565, 1807,  320,\n",
       "        949, 2695,   37,  704, 1544, 1405,   91,  166, 2249, 1607,  913,\n",
       "        507, 2228, 1539,  271, 1240, 1423, 2578,   54, 2700, 1606, 2568,\n",
       "       1858,  886, 1839, 1758, 2569, 2584,  514, 1338,  324, 2453,  469,\n",
       "        785, 2309, 1177,  976,  137,  505, 1366, 1595, 2241, 1206, 1747,\n",
       "       2705, 1551, 1264, 1699,  728,  450, 1699,  613, 1186,  123, 1372,\n",
       "        959,  583,  144, 2568,  189, 1126,  917, 1163, 1580,  144,  908,\n",
       "       1888, 1526,  105, 1252, 2175, 1470,  852, 1120,  943,  473, 1762,\n",
       "       1179])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'pollentwinbedwearingyourflannelshirtkeepsmewarmbackporchlaughterechoesbetweenclapsofthunderendofsummerstrandsofanabandonedkiteflutterinthewindinthehospiceanoutoftunepianohelpshersingwithoutwordshandinhandwhitepetalsblossomaswepassabandonedhomeanoldlifelaidtorestamongweedsandtreeshumidmorningthescentoflilacsfillseachbreathicypavementunopenedbudsshrinkandfallfromthetreesbloodmoonforcedtobecomeawomanlightrainlavenderblossominginasketchbookrainpuddlea'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"unknottingtears~cluecherrytouchpaymentsightsteamresumeskinfarmhousebook—cemeterysmileslostglideadvancecow'spointsbuddhaforkwriteadjustdove'smothslowerantiquebarkspraynightfall..floatscoffee.sparrowmothbottleinsomniamailwalksage?x'snight'svotepurplefireflies.pregnantpeppersvoyageurswar.collectedleftoverbugtissueclayenclosedstreetlightshonkingfrostedautumn'scocklisteningnestspinnedhurricanepenyearsmournersi’vepajamadripschinookpajamacuttinghospitalasksloadedfreecritiquesawhilevotebedtimehearseflourhisnatureawhileflickersrain—moorhensarcticipodsmellmenopausefatherheadacheforeclosurecleavageperhapshorizon\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 2728)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       7.9114013\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.9114\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.9035\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.8925\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.8672\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.7260\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.0242\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.1213\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.3540\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.0855\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.7798\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.8119\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 6.8695\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 6.7635\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 6.7424\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 6.6993\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 6.7228\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 6.6878\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 6.6469\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 6.6167\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 6.6285\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.5986\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 6.5696\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 6.5547\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 6.5501\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 6.5469\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 6.5210\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 6.5745\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 6.5545\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 6.5417\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 6.5117\n"
     ]
    }
   ],
   "source": [
    "#Training with 30 EPOCHS\n",
    "\n",
    "EPOCHS=30\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_30'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            698368    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 2728)           2796200   \n",
      "=================================================================\n",
      "Total params: 7,432,872\n",
      "Trainable params: 7,432,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_list):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_list]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # We pass the predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['too', 'drawn', 'hour', 'cock', 'schoolgirls', 'halfway', 'spring', 'home', 'on', 'i', 'one', 'watching', 'argument', 'left', 'black', 'farm', 'spring', 'an', 'oak', 'waiting', 'vanishes', 'just', 'changing', '...', 'sound', 'tombstones', '~', 'father', 'bloom', 'smile', 'train', 'young', 'bus', 'house', 'orgasm', 'bottle', 'moon', 'across', 'buried', 'stars', 'between', 'is', 'grave', 'autumn', 'last', 'the', 'stone', 'where', 'of', 'hospice', 'that', 'patio', 'desert', 'he', 'hot', 'the', 'on', 'night', 'huddle', 'full', 'pool', 'through', 'moon', 'starless', 'elder—', 'and', 'of', 'after', 'the', 'watching', 'of', 'by', 'scandal', 'and', 'car', 'of', 'dried', 'chill', 'breakfast', 'fork', 'winds', 'bus', 'train', 'a', 'another', 'long', 'year—', 'years', 'glides', 'life', 'the', 'avalanche', 'at', 'the', 'wait', 'along', 'buns', 'that', 'footprints', 'scramble', 'cracks', 'more', 'the', 'words', 'cereus', 'a', 'many', 'of', 'wind', 'birds', 'night', 'in', 'steps', 'shrink', 'between', 'candle', 'dust', 'incense', 'coal', 'the', 'cats', 'full', 'night', 'silt', 'no', 'up', 'the', 'grass', 'frogs', 'cracks', 'room', 'more', 'crescent', 'never', 'one', 'of', 'the', 'after', 'the', 'enclosed', 'carved', 'face', 'monthold', 'and', 'whistle', 'winds', 'life', 'each', 'writing', 'the', 'those', 'blossoms', 'a', 'winter', 'of', 'rain~~', 'night', 'a', 'wrinkles', 'of', 'left', 'of', 'winter', 'into', 'light', 'in', 'where', 'a', 'rain', 'meaty', 'find', 'harvest', 'smell', 'berry', 'on', 'the', 'friends', 'the', 'dust', 'roses', 'cup', 'grin', 'country', 'forced', 'fading', 'at', 'up', 'ironed', 'one', 'opens', 'fence', 'flea', 'comings', 'the', 'morning', 'bare', 'under', 'the', 'waiting', 'darkness', 'it', 'ride', 'woman', 'tracery', 'greyness', 'indian', 'sounds', 'sea', 'card', 'winds', 'day', 'together', 'tea', 'cry', 'cracked', 'a', 'my', 'dream', 'he', 'each', 'along', 'falling', 'night', 'piercing', 'a', 'is', 'rose', 'pool', 'before', 'night', 'emmett', 'dollhouse', 'yule', 'mouth', 'flashing', 'sunset', 'makes', 'star', 'says', 'homecoming', 'date', 'shine', 'polished', 'by', 'love', 'direction', 'eucalyptus', 'sleep', 'office', 'ghost', 'unties', 'replace', \"neighbor's\", 'she', 'arrived', 'chicken', 'roses', 'seeds', 'trash', 'louder', 'head', 'tibetan', 'note', 'alone', 'a', 'a', 'me', 'cold', 'petals', 'driver', 'flitting', 'tea', 'windscreen', 'of', 'the', 'moon', 'midnight', 'long', 'solders', 'back', 'of', 'ever.so.slowly', 'dusk', 'urn', 'at', 'tide', 'outside', 'bark', 'ordinary', 'the', 'the', 'quake', 'out', 'slowly', 'is', 'car', 'home', 'become', 'hare', 'farts', 'the', '...', 'deeper', 'with', 'pinkhaired', 'as', 'share', 'on', 'up', 'line', 'a', 'three', 'moon', 'fall', 'into', 'the', 'and', '.', 'climbing', 'streetlights', 'seeds', 'dust', 'trees', 'the', 'maple', 'long', 'house—', 'hidden', 'rain', 'outside', 'young', 'of', 'in', 'hear', 'cobra', 'another', 'gather', 'summer', 'star', 'snow', 'somebody', 'back', 'cubes', 'the', 'front', 'another', 'roses', 'city', 'ditch', 'beside', 'evening', 'rising', 'seed', 'coffin', 'a', 'flame', 'loaded', 'moonlight', 'down', 'warning', 'house!', 'the', 'my', 'bitter', 'her', 'endless', 'and', 'across', 'a', 'chilled', '8:16,', 'snow', 'through', 'the', \"i'm\", 'the', 'cries', 'a', 'the', 'the', 'the', 'of', 'windscreen', 'stairway', 'summer', 'her', 'the', 'all', 'painted', 'wasp', 'we', 'fingers', 'darkness', 'beside', 'playground', 'the', 'the', 'rusts', 'before', 'on', 'the', 'still', 'way', 'moon', 'cherrytree', 'pink', 'in', 'graveside', 'her', 'from', 'offshoring', 'or', 'just', 'black', 'after', 'old', 'too', 'cairn', 'full', 'of', 'the', 'just', 'circle', 'room', 'in', 'the', 'waiting', 'white', 'my', 'for', 'light', 'my', 'of', 'freeze', 'of', 'mixture', 'to', 'magpie?', 'phone', 'the', 'wisps', 'top', 'attention', 'with', 'clicks', 'party', 'me', 'the', 'rain', 'tea', 'an', 'of', 'the', 'beautiful', 'a', 'colors', 'the', 'reflect', 'shift', 'cool', 'bus', 'exgirl', 'mouth', 'the', 'her', 'homesick', 'rants', 'words', 'hereyes', 'full', 'daffodils', 'fall', 'traffic', 'in', 'a', 'all', 'with', 'of', 'her', 'on', 'rain', 'low', 'a', 'swirls', 'from', 'free', 'front', 'smells', 'heels', 'map', 'await', 'flat', 'silence', 'looking', 'trees', 'of', 'whistle', 'fall', 'darker', 'flood', 'blue', 'night', 'on', 'dead', 'through', 'no', 'heavy', 'on', 'sendai', 'screen', 'in', 'looking', 'with', 'a', 'someone', 'bows', 'the', 'a', 'magpie', 'faint', 'factory', 'old', 'the', 'moon', 'moves', 'old', 'clouds', 'an', 'still', 'window', 'carp', \"gerfalcon's\", 'in', 'spring', '.', 'in', 'glass', 'words', '.', 'the', 'a', 'my', 'house—', 'cloak', 'million', 'slip', 'spray', 'the', 'hotel', 'gets', 'on', 'finally', 'night', 'shifts', 'of', 'the', 'crunched', 'a', 'wind', 'polished', 'sipped', 'the', 'air', 'cries', 'autumn', 'between', \"robin's\", 'a', 'winter', 'night', 'takes', 'of', 'hill', 'summer', 'of', 'you', 'she', 'leaves—', 'a', 'by', 'spring', 'crushed', 'of', 'wind', 'speaks', 'age', 'to', 'the', 'bbq', 'us', 'distant', 'sunset', 'the', 'square', 'in', 'the', 'washing', 'a', 'in', 'thinner', 'bell', 'years—', 'with', 'moon', 'night', 'my', '.', 'moorhen', 'moon', 'spring', 'the', 'closer', 'building', 'blown', 'again', 'the', 'day', 'silence', 'a', 'of', 'crystalline', 'alone', 'imagine', 'wind', 'lilac', 'moving', 'the', 'drift', 'fills', \"neighbor's\", 'dinner', 'sumac', 'in', 'daffodils', 'going', 'left', 'outlines', 'the', 'and', 'laughter', 'in', 'a', 'has', 'summer', 'the', 'rain', 'sweats', 'the', 'angry', 'address', 'wine', 'head', 'the', 'the', 'autumn', 'huddled', 'sip', 'monk', 'was', 'sillage', 'the', 'of', 'new', 'the', 'a', 'forth', 'white', 'line', 'moonrise', 'silent', 'beneath', 'near', 'flowers', 'light', 'spring', 'with', 'twins', 'day', 'filling', 'train', 'her', 'dawn', 'all', 'year', 'shadows', 'a', 'falling', 'evening', 'fireflies', 'skeleton', 'dripping', 'line', 'first', 'tea', 'mattress', 'it', 'of', 'heat', 'autumn', 'of', 'silken', 'watch', 'season', 'a', 'breakup', 'of', 'as', 'in', 'teeth', 'the', 'winter', 'coffee.', 'her', 'from', 'barbed', 'motel', 'at', 'after', '...', 'touch', 'seaward', 'ordinary', 'spring', 'run', 'old', 'tea', 'unemployed', 'bus', 'a', 'all', 'a', 'climbing', 'the', 'open', 'leap', 'dusk', 'old', 'with', '...', 'way', 'passing', 'the', 'the', 'card', 'the', 'farm', 'in', 'state', 'tunnel', 'spring', \"stranger's\", 'afternoon...', 'train', 'window', 'same', 'treasures', 'market', 'long', 'dark', 'and', 'in', 'moon.', 'coffee', 'scents', 'among', 'sillage', \"robin's\", 'of', 'scents', 'an', 'desk', 'her', 'fog', 'old', 'indian', 'mountain', 'paper', 'on', 'rays', 'day', 'centered', 'the', 'of', 'jobs...', 'singing', 'with', 'the', 'old', 'on', 'stillness', 'heat', 'acorns', 'under', 'another', 'slow', 'dinner', 'the', 'same', 'on', 'moon', 'her', 'war', 'bear', 'head', 'abandoned', 'of', 'shrink', 'charred', 'of', 'name', 'offshoring', 'in', 'tinted', 'fork', 'a', 'of', 'a', 'kids', 'war', 'droplets', 'of', 'of', 'brittle', 'butterfly', 'of', 'the', 'march', 'freight', 'watching', 'local', 'of', 'the', 'memento', 'chill', 'salt', 'ports', 'cooking', 'moonlight', 'contrail', 'smog', 'the', 'basket', 'flames', 'flicker', 'faces,', 'tea', 'haze', 'cell', 'maple', 'freckles', 'dream', 'practices', 'left', 'the', 'adjust', 'moon', 'around', 'underfoot', 'declaration', 'my', 'in', 'buns', 'serious', 'someone', \"migrant's\", 'i', 'looks', 'in', 'the', 'girl', 'deny', 'at', 'a', 'at', 'blow', 'the', 'moon', 'day', 'late', 'a', 'pines', 'all', 'hospice', 'snores', 'playground', 'is', 'my', 'town', 'cloudlight', 'backs', 'cemetery', 'her', 'the', 'the', 'her', 'zazen', 'condor', 'of', 'the', 'golden', 'day', 'that', 'dust', 'clipping', 'of', 'full', 'sun', 'gunfire', 'carbide', 'sunflowers', 'mist', 'early', 'under', 'jam', 'a', 'memory', 'silence', 'between', 'crescent', 'on', 'lampshade', 'berry', 'answer', 'in', 'lull', 'hang', 'ocean', 'dawn', 'lines', 'mail', 'today', 'heat', 'more', 'neon', 'thoughts', 'finally', 'sky', 'my', 'middle', 'a', 'hurricane', 'wind', 'bookshelf', 'other', 'services', \"town's\", 'is', 'combiners', 'love', 'inside', 'desert', 'sun', 'in', 'the', 'wine', 'endless', 'roman', 'toward', 'ditch', 'winds', 'makes', 'to', 'emptied', 'i', 'somewhere', 'frost', 'the', 'of', 'food', 'wife', 'out', 'leaving', 'eyelids', 'small', 'midnight', 'pattering', 'spring', 'end', 'the', 'steam', 'wings', 'on', 'over', 'a', 'too', 'valley', 'through', 'of', 'of', 'around', 'takes', 'supermarket', 'of', 'passing', 'more', 'a', 'a', 'hand', 'howls', 'day']\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_list=['fishing', 'boats', 'colors', 'of', 'the', 'rainbow']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack]",
   "language": "python",
   "name": "conda-env-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
