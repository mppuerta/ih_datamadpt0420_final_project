{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/all_haiku.csv')\n",
    "\n",
    "data = data.iloc[0:1000]\n",
    "\n",
    "data['haiku'] = data['0']+' '+data['1']+' '+data['2']\n",
    "\n",
    "data['haiku'] = data['haiku'].apply(lambda x: str(x).strip().replace('-','').lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 50931 long\n",
      "Text has 2728 unique characters\n"
     ]
    }
   ],
   "source": [
    "#Leer los datos\n",
    "\n",
    "text = ''\n",
    "\n",
    "for i in data['haiku']:\n",
    "    text += i + ' '\n",
    "\n",
    "#vocab = sorted(set(text))\n",
    "vocab = sorted(set(list(filter(lambda x: x != \"\", text.split(\" \")))))\n",
    "\n",
    "print(f'Text is {len(text)} long')\n",
    "print(f'Text has {len(vocab)} unique characters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento del texto\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "txt_words = list(filter(lambda x: x != \"\", text.split(\" \")))\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in txt_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing\n",
      "boats\n",
      "colors\n",
      "of\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(txt_words)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n",
      "\"thesoundofgeesedrownedbythesoundofthetrainthismorningautumnsunmyshadowovertombstonesflyfishing;thesoundofthewindinthereeldecemberalongshadowjoinsanotherendofpathsnowflakesmeltingonthepondmorningfrostsheleavesfirsteveningwalksmelloftarbetweenpinesdachauablueskyabovethechimneysdeepautumn;theapplecolderinthetree.visitingthegravesstrongertheoctoberwindatmygrandparents'overthehedgeadragonflyeastabubbleburstsonsurfacefullmoonrainthewhitelilaclowmyhandon\"\n",
      "\"herhipfullmoonthreepetalsfallfromthepurpleconeflower...almostsummerinstantmessagemoonrevealsmoreofherselfeachnightoutofthewellbythebucketihuntamoonnudebeachastrangercoversmewithhisshadowgardenweddingunderthecherryblossomsthebride'sblushdeepensrainynewyorkfromthetenthstoreywindowblackumbrellasbloomdrunkonthebeachthemooninmysakecupdisappearsfaintlypurpleagainstthemoonpinesinthelightthelastlightofday~purplerhododendronsdissolveinthedarkwisteriabloomingbeforetheendof\"\n",
      "'rainthroughlace~thetraceryoffrostonglassrainfallsfromthetreesontheblueiriswinterbeachthreegreylinesofsand,seaandskywinterwhitepeoniesinfallingsnowlongillness–pinkdogwoodbloomingwithoutmelunchalfrescoleavingoutachairforthesuntheattentionhisdoggetshomelessmanrememberingasongfrommychildhoodplumblossomsfather’spillsthepaletteofautumnleavesendofsummerourmemoriesinzipfileswakingupwithfreckles&curlssummerbreaklongnightonmywindow—aspiderclimbingthemoontrain'\n",
      "'windowthefingerprintsfrompastjourneysoldloveletterthecrinklededgesofpoppypetalshisscentgonefromeveryroomwinterjasmineovernightsnowhissideofthebeduntouchedforesttrailrunningtotheendofmythoughtslearningtoeataroundbruiseswinterappleswinternightextendingmywordonscrabblethumbingthroughanoldrolodexwinterlightdandelionfieldmyvoicedissipatesinthewindtrailingbehindtheotherhikerstasteofdustsummerbreakthesunscattersmyfrecklessummer’sendinajarofshellsthesmellofsaltairearlymorningdewsqueezingthe'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehand\"\n",
      "Target data:  \"boatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0\n",
      "   input: (891, \"'fishing'\")\n",
      "   expected output: (257, \"'boats'\")\n",
      "Step     1\n",
      "   input: (257, \"'boats'\")\n",
      "   expected output: (516, \"'colors'\")\n",
      "Step     2\n",
      "   input: (516, \"'colors'\")\n",
      "   expected output: (1643, \"'of'\")\n",
      "Step     3\n",
      "   input: (1643, \"'of'\")\n",
      "   expected output: (2405, \"'the'\")\n",
      "Step     4\n",
      "   input: (2405, \"'the'\")\n",
      "   expected output: (1879, \"'rainbow'\")\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(f'Step     {i}')\n",
    "    print(f'   input: {int(input_idx), repr(idx2char[input_idx])}')\n",
    "    print(f'   expected output: {int(target_idx), repr(idx2char[target_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 2728) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           698368    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 2728)          2796200   \n",
      "=================================================================\n",
      "Total params: 7,432,872\n",
      "Trainable params: 7,432,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2487, 2577, 2081, 1700,  511, 2437, 2167, 2691, 1195, 1615, 1498,\n",
       "       2068, 2100, 1012,  416,  476, 2521, 2446, 2375, 1898, 1677, 1145,\n",
       "       1558, 1587, 1379, 2722, 1295, 2246, 1713,   18,  902, 2565,  894,\n",
       "       1442,  120, 2246,  890, 1457, 1047, 2127, 1238,  268, 1883, 1950,\n",
       "        971, 1059, 1898, 2519,  204, 2095, 2450, 1845, 1236, 1827, 1195,\n",
       "       1448, 2383, 1984, 1226, 2157, 2500, 1964, 1265, 1773,  838, 1087,\n",
       "        620,  983, 2349,  767, 2310, 1017,  905,  687,  119, 2712, 2703,\n",
       "         11, 1969, 1108, 1055,  627,  205, 2514, 1402, 2478,  658, 1380,\n",
       "        935, 2129,  608, 2726,  308,  150,  896, 2415,  393, 1787, 1859,\n",
       "        846])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'nightafluteplaysalongwiththerainlongexhaleasteadyrainonthetinroofsummerheatthepepperedscentofnasturtiumsafterrainamplifiedcricketsinthenightfreighttrainthoselittlestarssofarawayqueuetovotescentofsausagesinthecoldgreyskyfridayafternoonjustthebeesinlavenderspringgraffitiblossomalloverthewarehousewalllemonteaandlavenderoiltherainonrepeatopenwindowlemonscentedteatreeintherainsurfingwavesatinylizardoncorrugatedironmyownpacetinyflowerbloomsfromacrack'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"trashwalkedsharedpalecokethunderstorm—slowerworldhovernonamemiso!serviceshoesglidechalkclicktwotimetangleraysovenhibernatemovingnegativelogzillionkitespliffparties63flashingvoiceflakesmarkersasidesplifffishme?graveyardsilkeninkbornrainsrightfroggroom'sraystwinsberriesshimmertinyprisoninhibitionspotshovermarvelstearowsimprintslatstriproads'jamphotoshoppingfalteringhairsdamnedfurtherswayedgesstretchesgloveflavorditchashesyetyear...'romanhasgreynessdarkensberryturquoiselovingmakingtrail,deerlonefollowssiloscurve—brittlebackyardflamesthickercarrypinkpushesfarm\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 2728)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       7.9112773\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7.9113\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.9037\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.8928\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.8697\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.7601\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 8.5524\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "#Training with 10 EPOCHS\n",
    "\n",
    "EPOCHS=10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_10'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            808192    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 3157)           3235925   \n",
      "=================================================================\n",
      "Total params: 7,982,421\n",
      "Trainable params: 7,982,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_list):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_list]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # We pass the predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bows', 'the', 'mascara', 'buddha', 'to', 'strand', 'chickpea', 'face', 'morning', 'in', 'than', 'gloves', 'heard', 'looks', 'still', 'dandelions', 'city', 'of', 'of', 'always', 'bell', 'will', 'her', 'on', 'between', 'into', 'may', 'green', 'heat', 'me', 'rain', 'smell', 'off', 'covers', \"i'm\", 'sniffs', 'from', \"o'\", 'a', 'zen', 'moth', 'and', 'morning', 'rope', 'day', 'woman', 'bloomssudden', 'leaves', 'and', 'drums', 'through', 'full', 'day', \"summer's\", 'the', 'old', 'space', 'cracks', 'light', 'if', 'trying', 'around', 'for', 'to', 'end', 'hair', 'end', 'windshield', 'breeze', 'wool.estuary', 'feeling', 'and', 'in', 'and', 'endmoonlessness', 'faded', 'sun', 'time', 'sound', 'ricochets', 'my', 'child', 'wine', 'our', 'visiblerain', 'adjust', 'her', 'someone', 'bus', 'lilacs', 'late', 'finding', 'in', 'cloudsstart', 'sky', 'child', 'a', 'starsourdough', 'saxophoneshaving', 'directionnorth', 'my', '.', 'a', 'wipers', 'across', 'skies,', 'chill', 'a', '.', 'reading', 'empty', 'silence', 'day', 'his', 'old', 'of', 'bullet', 'short', 'a', 'revealed', 'at', 'thatchsheets', 'old', 'my', 'cold', 'a', 'somewhere', 'night', 'off', 'solstice', 'into', 'from', 'wind', 'late', 'workmonday', 'on', 'line', 'near', 'head', 'my', 'fireflies', 'sunset', 'and', 'heard', 'womanlight', 'keyboardafter', \"sailor's\", 'as', 'solstice', 'soft', 'they', 'lace', 'along', 'christmas', 'aster', 'mirror', 'rain', 'snow', 'memory', 'in', 'partsgarden', 'reading', 'supperfirst', 'smell', 'cat', 'another', 'refugee', 'ridges', 'of', 'buds', 'much', 'thoughts', 'undercurrent', 'hand', 'a', 'shrink', \"waterfall's\", 'temple', 'rain', 'morning', 'wind', 'supperfirst', '.', 'from', 'cottonwood', 'clattering', 'old', 'bbq', 'day', 'another', 'than', 'dawn', 'urn', 'shells', 'windin', 'robe', 'pale', 'at', 'cottonwood', 'night', 'a', 'points', 'fish', 'my', 'flow', 'night', 'late', 'fills', 'coffee', 'memorydusk', 'tents', 'older', 'song', 'long', 'cracksclimbing', '—', 'me', 'a', 'silence', 'pastalone', 'a', 'in', 'new', 'lingeriewinter', 'covers', 'with', 'hot', 'glide', 'she', 'war', 'tiny', 'pink', 'home', 'her', 'coochristmas', 'night', 'house', 'i', 'nails', 'season', 'traffic', 'mountains', 'silencegale', 'rosesinsomnia', 'sway', 'mist', 'first', 'faded', 'age?', 'rain', 'butterfly', 'rain', 'a', 'taxidusk', 'our', 'christmas', 'magnifying', 'winter', 'meets', 'and', 'rain', 'is', 'a', 'one', 'iris', 'until', 'light', 'on', '&', 'guardrail', 'tears', 'through', 'of', 'overdosenew', 'map', 'south', 'morning', 'by', 'moon', 'heart', 'attic', 'hair', '.', 'to', 'bridal', 'a', 'ticksdownpour', 'scent', 'at', 'sway', 'of', 'laugh', 'taxitrash', 'faded', 'changes', 'apricot', 'and', 'wife', 'facebook', 'and', 'my', 'burnt', 'sunfamily', 'falls', 'channel', 'home', 'into', 'lightning', 'tramways', 'joins', 'seem', 'steamed', 'tea', 'one', 'left', 'my', 'with', 'flowers', 'slowly', 'feeling', 'of', 'wire', 'grip', 'rain', 'he', 'rainbow', 'of', 'in', 'up', 'waitingtulips', 'clematis', '.', 'clay', 'a', 'lights', 'grass', 'day', 'and', 'my', 'on', 'and', 'older', '.', 'rain', 'memoriestrain', 'amongst', 'of', 'rain', 'faint', 'is', 'small', 'fancy', 'roomthe', 'night', 'apple', 'jam', 'rest', 'nearly', 'clouds', 'cat', 'reveals', 'space', 'petals', 'poppies', 'saved,', 'becomes', 'house', 'my', 'of', 'cup', 'the', 'runs', 'write', 'not', 'without', '.', 'migrant', 'summer', 'arm', 'leaves', 'lingering', 'snow', '.', 'summer', 'moon', '8:17', 'make', 'awhile', 'forty', 'same', 'spider', 'reflects', 'sharp', 'on', 'hairsweltering', 'cock', 'tails', 'bark', 'i', 'that', 'damned', 'warmth', 'loadedthe', 'toward', 'dance', 'last', 'not', 'we', 'at', 'my', 'urban', 'moon', 'sunlightfaraway', 'also', 'a', 'scent', 'a', 'of', 'in', 'day', 'filling', 'father', 'tvtraffic', 'critiques', 'first', 'movement', 'the', 'her', 'of', 'long', 'ball', 'raincold', 'malt', 'tracks', 'window', 'pot', 'home', 'not', 'my', 'smileimagine', 'with', 'a', '...', 'to', 'wasps', 'all', 'tangle', 'shadow', 'more', 'window', 'from', 'on', 'garden', 'she', 'mother', 'mixture', 'a', 'cold', 'ovenhaze', 'traffic', 'leaving', 'manremembering', 'sound', '...', 'barber', 'tightly', 'ink', 'against', \"alzheimer's\", 'our', 'of', 'grave', 'an', 'clicks', 'sounds', 'starry', \"leavestonight's\", 'smell', 'overlengthening', 'ratatouillebefore', 'mouse', 'day', 'by', 'old', 'bridge', '.', 'walls', 'a', 'smile', 'waitingtulips', 'for', 'other', 'filled', 'moon', 'with', 'found', 'blackout', 'spring', 'between', 'summer', 'of', 'weight', 'water...', 'touch', 'rain', 'petals', 'through', 'talk', 'summer', 'around', 'cut', 'against', 'a', 'spring', 'rain', 'and', 'old', 'critiques', 'an', 'and', 'my', 'an', 'rain', 'runsperched', 'age', 'me', 'friendright', 'full', 'pelican', 'to', 'lilac', 'me', 'clockwith', \"fox's\", 'their', 'patiowaiting', 'moor', \"father's\", 'skeleton', 'coin', 'red', 'within', 'trees', 'joggers', 'side', 'time', 'air', 'passengers', '...', 'before', 'from', 'minute', 'in', 'dead', 'an', 'stars', 'sway', 'grass', 'always', 'first', 'a', 'clock', 'man', 'up', 'day', 'that', 'too', 'my', 'a', 'postureslightning', 'bushfirefirst', 'in', 'betraysa', 'sky', 'ash', 'sky', 'morning', 'boat', 'more', 'my', 'morning', 'becomes', 'blooming', 'autumn', 'day', 'day', 'just', 'cream', 'moths', 'golden', 'last', 'and', 'thoughtslearning', 'warning', 'rain', 'gapthunderstorm', 'icicles', 'need', 'i', 'tries', 'asphaltno', 'snow', 'squinting', 'darkwisteria', 'lake', 'and', 'my', 'wet', 'of', 'owls', 'wrapped', 'hand', 'moon', 'march', '.', 'days', 'morning', 'child', 'garden', '?rumble', 'love', 'winter', 'are', 'my', 'in', 'out', 'garden', 'at', 'light', 'from', 'her', 'air', 'left', 'day', 'fallen', 'thunder', 'and', 'of', 'autumn', 'over', 'spring', 'of', 'dead', 'a', 'left', 'from', 'take', 'heard', 'roomthe', 'pine', 'the', 'into', 'the', 'sky', 'not', 'between', 'an', 'summer', 'so', 'our', 'window', 'all', 'blocks', 'another', 'sun', 'windowin', 'where', 'fallen', '.', 'my', 'wind', 'he', 'rail', 'tissue', 'to', 'some', 'coochristmas', 'at', \"summer's\", 'temple', '~', 'divorce', 'only', 'duty', 'a', 'winter', 'roadkillforeclosure', 'at', 'on', 'through', 'graveyard', 'sky', 'left', 'and', 'tattooed', 'in', 'moth', 'rain', 'smell', 'train', 'rainnew', 'of', 'of', 'lift', 'last', 'of', 'toward', 'watching', 'letter', '...', 'last', 'winter', 'pen', 'scent', 'moving', 'my', 'tiny', 'lightwhite', 'a', 'lampshadehedgerow', 'all', 'long', 'an', 'crinkled', 'still', 'all', 'fall', 'my', '—', 'new', 'cold', 'less', 'typos', 'lungs', 'a', 'still', 'to', 'is', 'sermon', 'on', 'two', 'bible', 'plus', 'light', 'on', 'illness', 'of', 'school', 'grow', 'pigtailed', 'condor', 'from', 'front', 'windowin', 'moon', 'pen', 'polenight', 'rain', \"son's\", 'afternoonel', 'a', 'plays', 'fireflies', 'i', 'entirely', 'a', 'old', 'crinkled', 'into', 'last', 'on', 'hall', 'few', 'stare', 'horizonbrittle', 'sun', 'in', 'from', 'end', 'no', 'are', 'in', 'playground', 'butterfly', 'rain', 'incenseblistering', 'no', 'moon', 'scent', 'with', 'in', 'question', 'becomes', 'solstice', 'faux', 'daughter', 'skyunemployed', 'living', 'a', 'trainstars', 'rain', 'inside', 'through', 'reflects', 'memoriestrain', 'of', 'with', 'the', 'green', 'love', 'cactus', 'of', 'a', 'beach', 'and', 'waits', 'with', 'so', 'against', 'my', 'stars', 'my', 'cold', 'during', 'last', 'fallen', 'mountainsa', 'the', 'waves', 'and', 'her', 'christmas', 'night', 'used', 'heard', 'hyacinthschilled', 'dock', 'so', 'a', 'shadow', 'fades', 'and', 'tram', 'city', 'he', 'through', 'soup', 'cries', 'nightthe', 'sidewalk', 'dreams', 'a', 'runvacant', \"blackbird's\", 'through', 'the', '.', 'baby', 'starless', 'she', 'fallen', 'line', 'stare', 'sunset', 'seeds', 'to', 'funerala', 'blue', 'we', 'escape', 'day', 'counting', 'even', 'obit', 'cat', 'love', 'proudlya', 'all', 'from', 'pouring', 'she', 'in', 'against', 'of', 'timestonehenge—', 'wolf', 'awayqueue', 'face', 'hand', 'new', 'rain', 'rain', 'rainsilent', 'geese', 'am', 'snail', 'glow', 'geesebetween', 'new', 'in', 'shines', 'still', 'all', 'winter', 'knownovember', 'shadows', 'slight,', 'day', 'reserves', 'of', 'after', 'i', 'windowharvest', 'after', 'in', 'rustsharing', 'dog', 'zip', 'rainspring', 'to', 'dog’s', 'from', 'insomnia', 'rise', 'rain', 'old', 'noticing', 'tea', 'through', 'in', 'a', 'on', \"night's\", '...', 'day', 'breeze', 'street', 'thunder', 'plastic', 'a', 'onlinemid', 'young', 'am', 'past', 'blossoms', 'in', 'fills', 'tearsdeath', 'is', 'namehouse', 'a', 'bottoms', 'into', 'rain', 'crickets', 'of', 'stubborn', 'a', 'februarylong', 'reedsechoes', 'handwriting—', 'a', 'last', 'on', 'petals', 'becomes', 'smell', \"wife's\", 'morning', 'r', 'chalk', 'snow', 'be', 'moon', 'to', 'shadow', 'trees', 'grey', 'lightsnight', 'by', 'gray', 'with', 'this', 'day', 'on', 'as', 'silentnothing', 'a', 'old', 'soft', 'day', 'heard', '.', 'her', 'at', 'cup', 'and', 'fence', 'finding', 'from']\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_list=['fishing', 'boats', 'colors', 'of', 'the', 'rainbow']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack]",
   "language": "python",
   "name": "conda-env-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
