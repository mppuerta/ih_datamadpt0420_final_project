{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/all_haiku.csv')\n",
    "\n",
    "data = data.iloc[0:1000]\n",
    "\n",
    "data['haiku'] = data['0']+' '+data['1']+' '+data['2']\n",
    "\n",
    "data['haiku'] = data['haiku'].apply(lambda x: str(x).strip().replace('-','').lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 50931 long\n",
      "Text has 2728 unique characters\n"
     ]
    }
   ],
   "source": [
    "#Leer los datos\n",
    "\n",
    "text = ''\n",
    "\n",
    "for i in data['haiku']:\n",
    "    text += i + ' '\n",
    "\n",
    "#vocab = sorted(set(text))\n",
    "vocab = sorted(set(list(filter(lambda x: x != \"\", text.split(\" \")))))\n",
    "\n",
    "print(f'Text is {len(text)} long')\n",
    "print(f'Text has {len(vocab)} unique characters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento del texto\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "txt_words = list(filter(lambda x: x != \"\", text.split(\" \")))\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in txt_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing\n",
      "boats\n",
      "colors\n",
      "of\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(txt_words)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n",
      "\"thesoundofgeesedrownedbythesoundofthetrainthismorningautumnsunmyshadowovertombstonesflyfishing;thesoundofthewindinthereeldecemberalongshadowjoinsanotherendofpathsnowflakesmeltingonthepondmorningfrostsheleavesfirsteveningwalksmelloftarbetweenpinesdachauablueskyabovethechimneysdeepautumn;theapplecolderinthetree.visitingthegravesstrongertheoctoberwindatmygrandparents'overthehedgeadragonflyeastabubbleburstsonsurfacefullmoonrainthewhitelilaclowmyhandon\"\n",
      "\"herhipfullmoonthreepetalsfallfromthepurpleconeflower...almostsummerinstantmessagemoonrevealsmoreofherselfeachnightoutofthewellbythebucketihuntamoonnudebeachastrangercoversmewithhisshadowgardenweddingunderthecherryblossomsthebride'sblushdeepensrainynewyorkfromthetenthstoreywindowblackumbrellasbloomdrunkonthebeachthemooninmysakecupdisappearsfaintlypurpleagainstthemoonpinesinthelightthelastlightofday~purplerhododendronsdissolveinthedarkwisteriabloomingbeforetheendof\"\n",
      "'rainthroughlace~thetraceryoffrostonglassrainfallsfromthetreesontheblueiriswinterbeachthreegreylinesofsand,seaandskywinterwhitepeoniesinfallingsnowlongillness–pinkdogwoodbloomingwithoutmelunchalfrescoleavingoutachairforthesuntheattentionhisdoggetshomelessmanrememberingasongfrommychildhoodplumblossomsfather’spillsthepaletteofautumnleavesendofsummerourmemoriesinzipfileswakingupwithfreckles&curlssummerbreaklongnightonmywindow—aspiderclimbingthemoontrain'\n",
      "'windowthefingerprintsfrompastjourneysoldloveletterthecrinklededgesofpoppypetalshisscentgonefromeveryroomwinterjasmineovernightsnowhissideofthebeduntouchedforesttrailrunningtotheendofmythoughtslearningtoeataroundbruiseswinterappleswinternightextendingmywordonscrabblethumbingthroughanoldrolodexwinterlightdandelionfieldmyvoicedissipatesinthewindtrailingbehindtheotherhikerstasteofdustsummerbreakthesunscattersmyfrecklessummer’sendinajarofshellsthesmellofsaltairearlymorningdewsqueezingthe'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"fishingboatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehand\"\n",
      "Target data:  \"boatscolorsoftherainbowashwednesdaytryingtoremembermydreamsnowymornpouringanothercupofblackcoffeeshortestdayflamesdanceintheovenhazehalfthehorsehiddenbehindthehouselowsuntheladyinredonhighheelsadventthepassingstrangerfartstarnabubbleintheicesnowflakesnewasphaltintheholescrystalnight'gustsofrainoutsiderainthesoundofahorsegallopingthroughleaveswinterstarssuddenlyawhiffofperfumehungryhalfofthemoonhiddenrainanotherleafdownshariathesoundofonehandclapping\"\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0\n",
      "   input: (891, \"'fishing'\")\n",
      "   expected output: (257, \"'boats'\")\n",
      "Step     1\n",
      "   input: (257, \"'boats'\")\n",
      "   expected output: (516, \"'colors'\")\n",
      "Step     2\n",
      "   input: (516, \"'colors'\")\n",
      "   expected output: (1643, \"'of'\")\n",
      "Step     3\n",
      "   input: (1643, \"'of'\")\n",
      "   expected output: (2405, \"'the'\")\n",
      "Step     4\n",
      "   input: (2405, \"'the'\")\n",
      "   expected output: (1879, \"'rainbow'\")\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(f'Step     {i}')\n",
    "    print(f'   input: {int(input_idx), repr(idx2char[input_idx])}')\n",
    "    print(f'   expected output: {int(target_idx), repr(idx2char[target_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 2728) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           698368    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 2728)          2796200   \n",
      "=================================================================\n",
      "Total params: 7,432,872\n",
      "Trainable params: 7,432,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2487, 2577, 2081, 1700,  511, 2437, 2167, 2691, 1195, 1615, 1498,\n",
       "       2068, 2100, 1012,  416,  476, 2521, 2446, 2375, 1898, 1677, 1145,\n",
       "       1558, 1587, 1379, 2722, 1295, 2246, 1713,   18,  902, 2565,  894,\n",
       "       1442,  120, 2246,  890, 1457, 1047, 2127, 1238,  268, 1883, 1950,\n",
       "        971, 1059, 1898, 2519,  204, 2095, 2450, 1845, 1236, 1827, 1195,\n",
       "       1448, 2383, 1984, 1226, 2157, 2500, 1964, 1265, 1773,  838, 1087,\n",
       "        620,  983, 2349,  767, 2310, 1017,  905,  687,  119, 2712, 2703,\n",
       "         11, 1969, 1108, 1055,  627,  205, 2514, 1402, 2478,  658, 1380,\n",
       "        935, 2129,  608, 2726,  308,  150,  896, 2415,  393, 1787, 1859,\n",
       "        846])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'nightafluteplaysalongwiththerainlongexhaleasteadyrainonthetinroofsummerheatthepepperedscentofnasturtiumsafterrainamplifiedcricketsinthenightfreighttrainthoselittlestarssofarawayqueuetovotescentofsausagesinthecoldgreyskyfridayafternoonjustthebeesinlavenderspringgraffitiblossomalloverthewarehousewalllemonteaandlavenderoiltherainonrepeatopenwindowlemonscentedteatreeintherainsurfingwavesatinylizardoncorrugatedironmyownpacetinyflowerbloomsfromacrack'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"trashwalkedsharedpalecokethunderstorm—slowerworldhovernonamemiso!serviceshoesglidechalkclicktwotimetangleraysovenhibernatemovingnegativelogzillionkitespliffparties63flashingvoiceflakesmarkersasidesplifffishme?graveyardsilkeninkbornrainsrightfroggroom'sraystwinsberriesshimmertinyprisoninhibitionspotshovermarvelstearowsimprintslatstriproads'jamphotoshoppingfalteringhairsdamnedfurtherswayedgesstretchesgloveflavorditchashesyetyear...'romanhasgreynessdarkensberryturquoiselovingmakingtrail,deerlonefollowssiloscurve—brittlebackyardflamesthickercarrypinkpushesfarm\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 2728)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       7.9112773\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7.9113\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.9037\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.8928\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.8697\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.7601\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 8.5524\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7.2950\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 7.5847\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5549\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.3524\n"
     ]
    }
   ],
   "source": [
    "#Training with 10 EPOCHS\n",
    "\n",
    "EPOCHS=10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_10'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            698368    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 2728)           2796200   \n",
      "=================================================================\n",
      "Total params: 7,432,872\n",
      "Trainable params: 7,432,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_list):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_list]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # We pass the predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listening', 'custom', 'old', 'wonderland', 'sniffs', 'assets', 'mother’s', 'she', 'dog', 'adjusts', 'hover', 'nasturtiums', 'steps', 'patio', 'tea', 'lull', 'beside', 'apology—', 'advance', 'pattering', 'break', 'sudden', 'only', 'evening', 'puff', 'she', \"customs'\", 'audible', 'deadheading', 'pendulum', 'sound', 'me', 'madeleine', 'dream', 'needle', 'tissue', 'afraid!', 'web', 'heavy', 'golfers', 'barely', 'midnight', 'this', 'blind', 'soap', 'flannel', 'his', 'this', 'embracing', 'with', 'returning', 'piano', 'lilac', 'start', 'fountain', 'carbide', 'bottoms', 'cottonwood', 'york', 'a', 'piano', 'fingers', 'slow', 'advent', 'years', 'cold', 'february', 'clay', 'cup', 'soft', 'lost', 'above', '.', 'rainbow', 'losing', 'beats', 'faces', 'floats', 'practices', 'tube', 'pattering', 'dissolve', 'moon', 'fields', 'lone', 'quietness', 'latch', 'silence', 'phone', 'cityscape', 'thicker', 'meditation', 'clematis', 'pavement', 'ports', 'lilac', 'sounds', 'cold', 'midnight', 'iris', 'untouched', 'bullet', 'halfway', 'adrift', 'growing', 'tattoo', 'sound', 'patience.', 'maimed', 'no', 'watches', 'dry', 'thin', '~', 'sheets', 'field', 'breeze', 'tang', 'petals', 'tired', 'suddenly', 'bevel', 'hospital', 'under', 'off', 'sweltering', 'slate', 'moans', 'out', 'croaking', 'housing', 'holes', 'fly,', 'onto', 'bedtime', 'gust', 'trek', 'measures', 'near', 'beach', '~', 'after', 'memory', 'meteor', 'drip', 'locks', 'trains', 'too', 'burnt', 'somewhere', 'minnesota', 'but', 'moons', 'the', 'direction', 'breeze', 'dream', 'windshield', 'gift', 'rain', 'forgetmenots', 'among', 'up', 'warm', 'place', 'whistle', 'looks', 'devils', 'holes', 'turquoise', 'left', 'quietness', 'sign', 'fired—', 'bench', 'last', \"children's\", 'crawling', 'hand', 'looking', 'life', 'bitter', 'tissue', 'morning', 'infant', 'smartphone', 'cleaning', 'drought', 'an', 'arriving', 'rainy', 'warnings', 'goes', 'pours', 'graffiti', 'sends', 'butterflies', 'of', 'honking', 'used', 'puddle', '…', 'without', 'border', 'unreadable', 'wolf', 'stockstill', 'father', 'candles', 'scents', 'glowing', 'avalanche', 'of', 'way', 'exchange', 'soft', 'glide', 'cracks', 'bright', 'bluebirds', 'moon', 'therapy', 'your', 'blocks', 'looking', 'still', 'eyes', 'whale', 'blues', 'of', \"she's\", 'nor', 'falling', 'fog', 'longing', 'central', 'fast', 'search', 'chilled', 'february', 'afghans', 'tiny', 'camp', 'tracks', 'toothless', 'peacefully', 'sailing', 'hair', 'horror', 'slight', 'apple', 'very', 'flowers', 'display', 'rusts', 'be', 'wool.', 'campfire', 'thinning', '60', 'time', 'waiting', 'seagulls', 'cooing', 'conformation', 'older', 'sparks', 'bedroom', 'steamed', 'soften', 'of', 'salt', 'cats', 'windscreen', 'so', 'plays', 'apricot', 'darker', 'mine', 'rain', 'sound', 'noname', 'darkens', 'watchtower', 'last', 'phone', 'father’s', 'more', 'office', 'used', 'schoolgirls', 'ash', 'of', 'call', 'dusk', 'apricot', 'maple', 'interrupted', 'wine', 'early', \"roads'\", 'flea', 'escape', 'sugar', 'takes', 'meaty', 'now', 'fancy', 'faded', 'wind', 'my', 'wind', 'bridge', 'cloudy', 'wings', 'scattering', 'my', 'jasmine', 'squinting', 'august', 'just', 'catching', 'hang', 'sprout', 'reflects', 'midnight', 'vacant', 'kitchen', 'battery', 'rises', 'stockings', 'almond', 'window', 'city', 'counting', 'memory', 'across', 'tattooed', 'soft', 'there', 'climb', 'corn', 'write', 'will', 'opposite', 'past', 'each', 'leaves', 'old', 'nude', 'days', 'gym', 'ice', 'hiring\"', 'someone', 'solstice', 'skin', 'slows', 'firefly', 'flannel', 'where', 'counting', 'hedges', 'pheasant', 'opposite', 'empty', 'a', 'hedgehog', 'whiter', 'unopened', 'hair', 'my', 'taking', 'white', 'housing', 'sound', 'summer', 'flagpole', 'of', 'pool', 'magpie?', 'wedding', 'greedily', 'hospice', 'scent', 'street', 'shadows', 'our', \"children's\", 'freesias', 'haiku', 'flannel', 'new', 'on', 'bouquet', 'onto', 'dream', 'too', 'holes', 'bruises', 'stirs', '~', 'farewell', 'share', 'begins', 'dead...', 'amid', 'sign', 'gone', 'scent', 'evening', 'date', 'after', '60', 'spliff', 'roman', 'spring', 'through', \"till's\", 'hiroshima', 'desert', 'bloomed', 'loving', 'firefly', 'terrorists', 'tracks', 'candles', 'salt', 'close', 'frost', 'gull', 'always', 'moon', 'traveling', 'of', 'tree', 'fireflies', 'bridge', 'christmas', 'man', 'await', 'exgirl', 'about', 'silence', 'bench', \"convict's\", 'files', 'declaration', 'summer', 'proudly', 'moon.', 'branches', 'ads', 'bald', 'mist', 'welcome', 'a', 'morning.', 'alone', 'after', 'branches', 'early', 'man', 'print', 'payment', 'wipers', 'leaves', 'a', 'out', 'roof', \"grandparents'\", 'viagra', 'in', 'roadside', 'light', 'roses', 'shadows', 'homeless', 'longer', 'a', 'shy', 'post', 'of', 'angels', 'nourishing', 'thickens', 'drawn', 'passes', 'deepens', 'whistle', 'paws', 'heavy', 'book', 'crickets', 'frost', 'field', 'pen', 'gray', 'light', 'off', 'bird', 'copper', 'falls', 'through', 'learning', 'spitting', 'dusk', 'dandelions', 'thicker', 'fog', 'spring', 'spring', 'mandarin', 'seeds', 'rising', 'daybreak', 'office', 'gym', 'heighten', 'hospice', 'news', 'girl', 'loon', 'crashing', 'juice', 'things', 'golfers', 'mandarin', 'pumpkin’s', 'spray', 'flea', 'haïku', 'the', 'amid', 'sundown', 'blossoms', 'whale', 'granite', 'tells', \"year's\", 'of', 'like', 'mirror', 'scraps', 'it', 'sugar', 'thoughts', 'snow', 'new', 'of', 'crickets', 'waiting', 'traffic', 'windscreen', 'blind', 'cracks', 'a', 'weeds', 'away', 'bus', 'sharing', 'she', 'silken', 'cat', 'gone', 'calling', 'skin', 'winds', 'memorial', 'flood', 'carbuncles', 'after', 'purple', 'condor', 'a', 'train', 'mixture', 'early', 'abandoned', 'lantern', 'cracks', 'again', 'under', 'of', 'puddle', 'dawn', 'morning', 'park', 'dull', 'pendulum', 'combiners', 'women', 'rereads', 'a', 'forgetmenots', 'appear', 'spider', 'sex', 'motorcycles', \"road's\", 'darker', 'cool', 'flowers', 'snow', 'deepening', 'top', 'words', 'chrysanthamums', 'we', 'exchange', 'forest', 'year', 'only', 'around', 'faux', 'moonlit', 'trails', 'pond', 'date—', 'dusk', \"grandparents'\", 'twilight', 'leaf', 'abandoned', 'filled', 'rust', 'also', 'car', 'as', 'peach', 'first', 'inch', 'come', 'halfpriced', 'slow', 'pots', 'curve', 'from', 'mailbox', 'plucks', 'midnight', 'dinner', 'system', 'candle', 'washed', 'all', 'remains', 'friday', 'winds', 'sudden', 'are', 'cheesecake', 'dusk', 'cold', '.', 'turquoise', 'daily', 'buddha', 'dog’s', 'dogs', 'sidewalk', 'eyes', 'inspect', 'lace', 'some', 'and', 'carriage', 'ward', 'drizzle', 'your', 'louder', 'papers', 'born', 'hot', 'mixed', 'wind', 'clink', 'among', 'so', 'roses', 'drops', 'ash', 'lowering', 'rainwater', 'my', 'storm', 'fence', 'toward', 'gazing', 'pajama', 'letters', 'running', 'meditation', 'of', 'home', 'just', 'leaves', 'first', 'clear', 'unreadable', 'hair', 'carbuncles', 'wind', 'autumn', 'work', 'rubber', 'way', 'together', 'wife', 'petals', 'on', 'and', 'idiot', 'a', 'tea...', 'sun', 'flavor', '&', 'afraid', 'lingers', 'glories', 'fog', 'spring', 'some', 'sweet', 'light', 'tram', '...', 'slate', 'job', 'floats', 'lies', 'of', 'slows', 'bloom', 'waiting', 'sound', 'and', 'cries', 'thunder', 'schoolhouse', 'tightly', 'her—', 'neighbors', 'behind', '~', 'spider', 'pale', 'old', 'me', 'ghetto', 'cloudy', 'frosted', 'croaking', 'alone', 'playground', 'urologist’s', 'traveling', 'out', 'still', 'steps', 'silver', 'steady', 'horses', 'cheeries', 'dawn', \"cow's\", 'moons', 'overcast', 'hill', 'arctic', 'pause', 'blinded', \"cat's\", 'afghans', 'huddle', 'echoes', 'vine', 'keyboard', 'where', 'playground', 'lullabies', 'gull?', 'first', 'more', ':', 'smelling', 'light', 'fog', \"cat's\", 'essence', 'flame', 'deep', 'wires', 'puts', 'menopause', 'body', 'lights', 'me', 'an', 'beer', 'my', 'my', 'deep', 'malt', 'cooing', 'writing', 'women', 'moon', 'quarrel', 'horror', 'clear', 'thinner', 'calling', 'rainy', 'carefully', 'walls', 'incensesmoked', 'sunlight', 'we', 'dream', 'moonlit', 'guest', 'brightly', 'warehouse', 'amplified', 'mirror', 'bed', '~', 'magpie?', 'wrapped', 'wipers', 'shoots', 'thunder', 'hike', 'b', 'scars', 'sweet,', 'louder', 'leaves—', 'harvest', 'hedge', 'wonderland', 'arm', 'teeth', 'teabag', 'smartphone', 'pregnant', 'each', 'clock', 'claps', \"else's\", 'time', 'lilac', 'outlines', 'mirror', 'blinded', \"valentine's\", 'crescent', 'wedding', 'words', 'first', 'spider', 'pond', 'cherrytree', 'trail', 'old', 'sky', 'pull', 'two', 'barn', 'mellow', 'shadows', 'mirror', 'hardware', 'shaved', 'suitcase', 'tremble', 'moon...', 'puddle', 'heavy', 'night', 'puddle', 'love', 'tea', 'on', 'couple', 'turquoise', 'finger', 'windless', 'hundreds', 'which', 'cherrytree', 'facebook', 'nose', 'nothing', 'moorhens', 'shy', 'finally', 'soft', 'butterfly', 'garden', 'autumn', 'against', 'mourners', 'crickets', 'mill', 'pines', 'birds', \"mill's\", 'birds', '...', '~', 'lavender', 'lullaby', 'uniform', 'fireflies', 'empty', 'evening', 'sweltering', 'summer', 'bell', 'of', 'shower', 'blonde', 'watchtower', 'dark', 'sisters', 'through', 'horror', 'trick', 'asphalt', 'chatter', 'halfway', 'flies', 'trash', 'dusty', 'cracked', 'ice', 'white', 'saturday', 'clattering', 'enclosed', \"veteran's\", 'flat', 'gaza', 'white', \"spider's\", 'photo', 'summer', 'afternoon', 'horse', 'sap', 'this', 'cover', 'repeat', 'pole', 'lemon', 'else', 'empty', 'tenth', 'pine', 'unreadable', 'moving', 'rusting', 'and', 'ticks', 'friday', 'still', 'little', 'its', 'blue', 'death', 'at', 'garden', 'flat', 'spring…', 'smart', 'but', 'snowflakes', 'payment', 'cracks', 'news', 'wedding', 'somewhere', 'john', 'saxophone', 'scraps', 'her', 'of', '—', 'journeys', 'grassy', 'copper', 'beside', 'calls', 'menopause', '8:17', 'perfume', 'seeds']\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_list=['fishing', 'boats', 'colors', 'of', 'the', 'rainbow']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack]",
   "language": "python",
   "name": "conda-env-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
