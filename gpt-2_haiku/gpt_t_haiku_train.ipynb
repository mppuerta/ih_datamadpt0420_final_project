{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-t_haiku_train",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKxNiXLV850"
      },
      "source": [
        "#Install virtualenv to support older versions of tensorflow\n",
        "!pip3 install virtualenv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj-w4jlYRrYv"
      },
      "source": [
        "#Create virtual environment\n",
        "!virtualenv ironhack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7B3bHm4Rrbd"
      },
      "source": [
        "#Install the version of tensorflow the model work's with\n",
        "!source /content/ironhack/bin/activate; pip3 install tensorflow==1.12.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o4Qfd3BRrgf",
        "outputId": "d13007d6-7660-4de9-ef6e-4d2ff2122925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Clone repo containing the model\n",
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 375, done.\u001b[K\n",
            "remote: Total 375 (delta 0), reused 0 (delta 0), pack-reused 375\u001b[K\n",
            "Receiving objects: 100% (375/375), 4.43 MiB | 22.66 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCON92ZRrlo",
        "outputId": "4619246c-6e13-4d84-a0f9-d6cbce77dc72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Install libraries in the requirements file\n",
        "cd gpt-2\n",
        "!source /content/ironhack/bin/activate; pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_s3YAGBRrxL",
        "outputId": "f0b7d0fa-0494-4762-a4ab-d71c78f75817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Mount drive to later save the checkpoints generated\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB7qRs_zRr2h",
        "outputId": "fcc8bdfe-1dea-44bc-9185-ae2cf3633f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Download the model\n",
        "!source /content/ironhack/bin/activate; python3 download_model.py 117M\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 868kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 54.0Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.00Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:08, 58.3Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 5.00Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 56.4Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 49.9Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59BS9KEfRrwQ"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0UZpSafRrt6"
      },
      "source": [
        "#Train the model\n",
        "!source /content/ironhack/bin/activate; PYTHONPATH=src ./train.py --dataset 'processed_data/haikus15000.txt' --model_name '117M'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9QKA1BSr2PV"
      },
      "source": [
        "#Save checkpoints\n",
        "!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/checkpoint/run3_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FizwgfJgY8r4"
      },
      "source": [
        "#Run to load trained model\n",
        "!source /content/ironhack/bin/activate; cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8x-XWIHbJ4K"
      },
      "source": [
        "#Run to generate text from trained model\n",
        "!source /content/ironhack/bin/activate; python3 src/generate_unconditional_samples.py --model_name \"117M\" | tee /tmp/samples"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}