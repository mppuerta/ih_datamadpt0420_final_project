{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/all_haiku.csv')\n",
    "\n",
    "data['haiku'] = data['0']+' '+data['1']+' '+data['2']\n",
    "\n",
    "data['haiku'] = data['haiku'].apply(lambda x: str(x).strip().replace('-',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 9860268 long\n",
      "Text has 105 unique characters\n"
     ]
    }
   ],
   "source": [
    "#Leer los datos\n",
    "\n",
    "text = ''\n",
    "\n",
    "for i in data['haiku']:\n",
    "    text += i + os.linesep\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "    \n",
    "print(f'Text is {len(text)} long')\n",
    "print(f'Text has {len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento del texto\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "i\n",
      "s\n",
      "h\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_lenght+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fishing boats colors of the rainbow\\nash wednesday trying to remember  my dream\\nsnowy morn pouring ano'\n",
      "'ther cup of black coffee\\nshortest day flames dance in the oven\\nhaze half the horse hidden behind the '\n",
      "'house\\nlow sun the lady in red on high heels\\nadvent the passing stranger farts\\ntarn a bubble in the ic'\n",
      "\"e\\nsnowflakes new asphalt in the holes\\nCrystal Night'    gusts of rain       outside\\nrain the sound of\"\n",
      "' a horse galloping through leaves\\nwinter stars suddenly a whiff of perfume\\nhungry half of the moon hi'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'fishing boats colors of the rainbow\\nash wednesday trying to remember  my dream\\nsnowy morn pouring an'\n",
      "Target data:  'ishing boats colors of the rainbow\\nash wednesday trying to remember  my dream\\nsnowy morn pouring ano'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0\n",
      "   input: (66, \"'f'\")\n",
      "   expected output: (69, \"'i'\")\n",
      "Step     1\n",
      "   input: (69, \"'i'\")\n",
      "   expected output: (79, \"'s'\")\n",
      "Step     2\n",
      "   input: (79, \"'s'\")\n",
      "   expected output: (68, \"'h'\")\n",
      "Step     3\n",
      "   input: (68, \"'h'\")\n",
      "   expected output: (69, \"'i'\")\n",
      "Step     4\n",
      "   input: (69, \"'i'\")\n",
      "   expected output: (74, \"'n'\")\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(f'Step     {i}')\n",
    "    print(f'   input: {int(input_idx), repr(idx2char[input_idx])}')\n",
    "    print(f'   expected output: {int(target_idx), repr(idx2char[target_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack]",
   "language": "python",
   "name": "conda-env-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
